{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import statements\n",
    "\n",
    "import numpy as np\n",
    "import html\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "\n",
    "#import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, Input\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Embedding, Input, Lambda\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import SGD, Adagrad\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, GlobalMaxPooling1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import keras.callbacks\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, scale\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "isTrain = 'Test'\n",
    "path1 = 'CombinedAcc/'+isTrain+'CombinedFile_walking.csv'\n",
    "path2 = 'CombinedAcc/'+isTrain+'CombinedFile_sitting.csv'\n",
    "path3 = 'CombinedAcc/'+isTrain+'CombinedFile_standing.csv'\n",
    "path4 = 'CombinedAcc/'+isTrain+'CombinedFile_laying.csv'\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "\n",
    "df = pd.read_csv(path1,index_col=None, header=0)\n",
    "list_.append(df)\n",
    "df = pd.read_csv(path2,index_col=None, header=0)\n",
    "list_.append(df)\n",
    "df = pd.read_csv(path3,index_col=None, header=0)\n",
    "list_.append(df)\n",
    "df = pd.read_csv(path4,index_col=None, header=0)\n",
    "list_.append(df)\n",
    "\n",
    "frame = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.head\n",
    "frame.to_csv('CombinedAcc/CombinedFile_'+isTrain+'.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1518920358183</td>\n",
       "      <td>-0.454792</td>\n",
       "      <td>-0.473941</td>\n",
       "      <td>7.137835</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1518920358187</td>\n",
       "      <td>-0.397344</td>\n",
       "      <td>-0.339897</td>\n",
       "      <td>7.080388</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1518920358191</td>\n",
       "      <td>-0.320748</td>\n",
       "      <td>-0.320748</td>\n",
       "      <td>7.080388</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1518920358195</td>\n",
       "      <td>-0.359046</td>\n",
       "      <td>-0.205853</td>\n",
       "      <td>7.137835</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1518920358199</td>\n",
       "      <td>-0.397344</td>\n",
       "      <td>-0.110107</td>\n",
       "      <td>7.176133</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1518920358203</td>\n",
       "      <td>-0.435643</td>\n",
       "      <td>-0.129257</td>\n",
       "      <td>7.156984</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1518920358207</td>\n",
       "      <td>-0.454792</td>\n",
       "      <td>-0.148406</td>\n",
       "      <td>7.156984</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1518920358211</td>\n",
       "      <td>-0.435643</td>\n",
       "      <td>-0.129257</td>\n",
       "      <td>7.118686</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1518920358215</td>\n",
       "      <td>-0.512239</td>\n",
       "      <td>-0.205853</td>\n",
       "      <td>7.061238</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1518920358218</td>\n",
       "      <td>-0.627134</td>\n",
       "      <td>-0.110107</td>\n",
       "      <td>7.099536</td>\n",
       "      <td>walking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              0         1         2         3        4\n",
       "0           0  1518920358183 -0.454792 -0.473941  7.137835  walking\n",
       "1           1  1518920358187 -0.397344 -0.339897  7.080388  walking\n",
       "2           2  1518920358191 -0.320748 -0.320748  7.080388  walking\n",
       "3           3  1518920358195 -0.359046 -0.205853  7.137835  walking\n",
       "4           4  1518920358199 -0.397344 -0.110107  7.176133  walking\n",
       "5           5  1518920358203 -0.435643 -0.129257  7.156984  walking\n",
       "6           6  1518920358207 -0.454792 -0.148406  7.156984  walking\n",
       "7           7  1518920358211 -0.435643 -0.129257  7.118686  walking\n",
       "8           8  1518920358215 -0.512239 -0.205853  7.061238  walking\n",
       "9           9  1518920358218 -0.627134 -0.110107  7.099536  walking"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head(10)\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp=open('CombinedAcc/CombinedFile_Train.csv',\"r\")\n",
    "wfp=open(\"CombinedAcc/TrainFinalFile.csv\",\"w\")\n",
    "\n",
    "i = 0\n",
    "for line in fp:\n",
    "    i +=1\n",
    "    if i==1:\n",
    "        continue;\n",
    "    #print(line)\n",
    "    l=line.split(\",\")\n",
    "    s=l[6].strip('\\n')\n",
    "    if s=='sitting' or s=='standing' or s=='walking' or s=='laying_down':\n",
    "        temp_string = l[3]+','+l[4]+','+l[5]+','+l[6] \n",
    "        wfp.write(temp_string)\n",
    "\n",
    "\n",
    "fp.close()\n",
    "wfp.close()\n",
    "\n",
    "fp=open('CombinedAcc/CombinedFile_Test.csv',\"r\")\n",
    "wfp=open(\"CombinedAcc/TestFinalFile.csv\",\"w\")\n",
    "\n",
    "i = 0\n",
    "for line in fp:\n",
    "    i +=1\n",
    "    if i==1:\n",
    "        continue;\n",
    "    #print(line)\n",
    "    l=line.split(\",\")\n",
    "    s=l[6].strip('\\n')\n",
    "    if s=='sitting' or s=='standing' or s=='walking' or s=='laying_down':\n",
    "        temp_string = l[3]+','+l[4]+','+l[5]+','+l[6] \n",
    "        wfp.write(temp_string)\n",
    "\n",
    "\n",
    "fp.close()\n",
    "wfp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamal/miniconda3/lib/python3.6/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# LSTM \n",
    "def create_data(filename):\n",
    "    from scipy import stats\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "    columns = [ 'x-axis', 'y-axis', 'z-axis','activity']\n",
    "    df = pd.read_csv(filename, header = None, names = columns)\n",
    "\n",
    "    N_TIME_STEPS = 250\n",
    "    N_FEATURES = 3\n",
    "    step = 1000\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - N_TIME_STEPS, step):\n",
    "        xs = df['x-axis'].values[i: i + N_TIME_STEPS]\n",
    "        ys = df['y-axis'].values[i: i + N_TIME_STEPS]\n",
    "        zs = df['z-axis'].values[i: i + N_TIME_STEPS]\n",
    "        label = stats.mode(df['activity'][i: i + N_TIME_STEPS])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)\n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    return(reshaped_segments,labels)\n",
    "\n",
    "X_train, y_train = create_data('CombinedAcc/TrainFinalFile.csv')\n",
    "X_test, y_test = create_data('CombinedAcc/TestFinalFile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 250, 3)            0         \n",
      "_________________________________________________________________\n",
      "lstm_layer (GRU)             (None, 250, 32)           3456      \n",
      "_________________________________________________________________\n",
      "lstm_layer_1 (GRU)           (None, 32)                6240      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 12,068\n",
      "Trainable params: 12,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 12594 samples, validate on 1400 samples\n",
      "Epoch 1/10\n",
      "12594/12594 [==============================] - 46s - loss: 1.0773 - acc: 0.5021 - val_loss: 1.3348 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "12594/12594 [==============================] - 52s - loss: 0.8962 - acc: 0.6231 - val_loss: 1.3108 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "12594/12594 [==============================] - 53s - loss: 0.7886 - acc: 0.6976 - val_loss: 1.3385 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "12594/12594 [==============================] - 52s - loss: 0.7014 - acc: 0.7261 - val_loss: 1.1893 - val_acc: 0.0636\n",
      "Epoch 5/10\n",
      "12594/12594 [==============================] - 50s - loss: 0.6633 - acc: 0.7390 - val_loss: 1.5046 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "12594/12594 [==============================] - 50s - loss: 0.6521 - acc: 0.7395 - val_loss: 1.3815 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "12594/12594 [==============================] - 48s - loss: 0.6308 - acc: 0.7494 - val_loss: 1.4850 - val_acc: 0.0836\n",
      "Epoch 8/10\n",
      "12594/12594 [==============================] - 50s - loss: 0.6161 - acc: 0.7558 - val_loss: 1.6182 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "12594/12594 [==============================] - 49s - loss: 0.5920 - acc: 0.7631 - val_loss: 1.3467 - val_acc: 0.1471\n",
      "Epoch 10/10\n",
      "12594/12594 [==============================] - 49s - loss: 0.5823 - acc: 0.7720 - val_loss: 1.3885 - val_acc: 0.1707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f524e6a8da0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_TIME_STEPS = 250\n",
    "N_FEATURES = 3\n",
    "step = 250\n",
    "input_layer = Input(shape=(N_TIME_STEPS,N_FEATURES,), dtype='float32', name='input_layer')\n",
    "#cnn_layer = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu',name = 'cnn_layer') (input_layer)\n",
    "#pool_layer = MaxPooling1D(pool_size = 2,name = 'pool_layer')(cnn_layer)\n",
    "\n",
    "#cnn_layer = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu',name = 'cnn_layer_1') (pool_layer)\n",
    "#pool_layer = MaxPooling1D(pool_size = 2,name = 'pool_layer_1')(cnn_layer)\n",
    "\n",
    "#cnn_layer = Conv1D(filters=8, kernel_size=3, padding='same', activation='relu',name = 'cnn_layer_2') (pool_layer)\n",
    "#pool_layer = MaxPooling1D(pool_size = 2,name = 'pool_layer_2')(cnn_layer)\n",
    "\n",
    "#dense_layer = Flatten()(pool_layer)\n",
    "lstm_layer = GRU(32,dropout=0.2, recurrent_dropout=0.2, name='lstm_layer', return_sequences=True)(input_layer)\n",
    "lstm_layer = GRU(32,dropout=0.2, recurrent_dropout=0.2, name='lstm_layer_1')(lstm_layer)\n",
    "dense_layer = Dense(64,activation = 'sigmoid',name = 'dense_1')(lstm_layer)\n",
    "dense_layer = Dense(4,activation = 'softmax',name='dense_2')(dense_layer)\n",
    "\n",
    "model = Model(inputs = input_layer,outputs = dense_layer)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,validation_split = 0.1, epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302/302 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1594543591240385, 0.43046357615894038]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
